{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb45d8a-a8a9-44b6-8297-597f602fa0b2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üéì LearnMate: A Personalized AI Learning Coach\n",
    "\n",
    "LearnMate is a Retrieval-Augmented Generation (RAG) system designed to act as an AI learning coach. It provides personalized learning pathways and course recommendations based on a user's interests, skill level, and career goals.\n",
    "\n",
    "The project is built as a self-contained Python notebook, making it easy to share and run.\n",
    "\n",
    "-----\n",
    "\n",
    "### üí° Proposed Solution\n",
    "\n",
    "LearnMate's core function is to guide students by:\n",
    "\n",
    "  * **Providing Personalized Pathways**: It suggests specific courses and learning roadmaps in domains like Frontend Development, Cybersecurity, and UI/UX.\n",
    "  * **Offering Contextual Advice**: It explains why a particular course fits a user's goals and provides general tips for learning and progression.\n",
    "  * **Creating an Interactive Interface**: The project uses Gradio to create a user-friendly web interface, allowing for a conversational experience.\n",
    "\n",
    "-----\n",
    "\n",
    "### ‚öôÔ∏è Tools & Technologies\n",
    "\n",
    "This project is built using the following key technologies:\n",
    "\n",
    "  * **LangChain**: The primary framework for building the RAG pipeline.\n",
    "  * **Replicate**: Used to access and run the `ibm-granite/granite-3.3-8b-instruct` large language model.\n",
    "  * **Gradio**: Used to create a simple and interactive web interface for the application.\n",
    "  * **FAISS**: An efficient library for vector search, used here to create a vector store for the knowledge base.\n",
    "  * **HuggingFace Embeddings**: A model from Hugging Face used to generate the vector embeddings for the text data.\n",
    "  * **Python-dotenv**: A crucial library for securely loading API keys from a `.env` file.\n",
    "\n",
    "-----\n",
    "\n",
    "### üöÄ Getting Started\n",
    "\n",
    "Follow these steps to set up and run the LearnMate project on your local machine.\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "  * Python 3.8+\n",
    "  * A Replicate API Token\n",
    "\n",
    "#### Installation\n",
    "\n",
    "1.  **Clone the Repository**:\n",
    "    ```bash\n",
    "    git clone https://github.com/your-username/your-repo-name.git\n",
    "    cd your-repo-name\n",
    "    ```\n",
    "2.  **Create a `.env` file**:\n",
    "    Create a file named `.env` in the root directory and add your Replicate API key:\n",
    "    ```\n",
    "    REPLICATE_API_TOKEN=\"your_token_here\"\n",
    "    ```\n",
    "3.  **Install Dependencies**:\n",
    "    The required libraries are listed in `requirements.txt`. Install them by running:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "#### Running the Application\n",
    "\n",
    "Open the `LearnMate.ipynb` file in a Jupyter environment (like Jupyter Notebook, JupyterLab, or VS Code) and run all the cells in order. This will launch the Gradio interface, and a shareable link will be provided in the output.\n",
    "\n",
    "-----\n",
    "\n",
    "### üìÑ How It Works\n",
    "\n",
    "1.  **Dependencies & Authentication**: The notebook first installs all necessary libraries and then securely loads the Replicate API token from the `.env` file.\n",
    "2.  **RAG Pipeline**:\n",
    "      * **Data Loading**: A small \"knowledge base\" of courses is created in a text file (`learnmate_courses.txt`).\n",
    "      * **Text Splitting**: The text is split into smaller chunks to prepare it for embedding.\n",
    "      * **Embedding & Vector Store**: `HuggingFaceEmbeddings` is used to convert the text chunks into vectors, which are then stored in a `FAISS` vector database for efficient retrieval.\n",
    "3.  **LLM & RAG Chain**:\n",
    "      * A connection to the **IBM Granite 3.3B Instruct** model on Replicate is established.\n",
    "      * A **Retrieval-Augmented Generation (RAG)** chain is constructed. This chain retrieves the most relevant information from the vector store based on the user's query and then uses the large language model to generate a natural, helpful response.\n",
    "4.  **User Interface**: The `gradio` library creates a simple web interface that allows a user to type a question and receive a response from the AI coach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e76fdff-3935-4e34-8f92-6671bfc7bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install replicate langchain gradio langchain_community langchain_huggingface faiss-cpu transformers python-dotenv\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the API token is loaded\n",
    "replicate_api_token = os.getenv(\"REPLICATE_API_TOKEN\")\n",
    "if not replicate_api_token:\n",
    "    raise ValueError(\"REPLICATE_API_TOKEN not found. Please set it in your .env file or Colab Secrets.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "import gradio as gr\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Replicate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# IBM Granite model via Replicate\n",
    "model_path = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = Replicate(\n",
    "    model=model_path, \n",
    "    replicate_api_token=replicate_api_token, # Use the securely loaded token\n",
    "    input={\"temperature\": 0.1, \"max_length\": 500}\n",
    ")\n",
    "\n",
    "# üìö Sample LearnMate knowledge base\n",
    "filename = \"learnmate_courses.txt\"\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "Frontend Development Pathway:\n",
    "1. HTML & CSS Fundamentals (Beginner) ‚Äî Learn basic web page structure and styling.\n",
    "2. JavaScript Essentials (Beginner) ‚Äî Add interactivity to websites.\n",
    "3. React for Developers (Intermediate) ‚Äî Build dynamic, modern web apps.\n",
    "4. Frontend Capstone Project (Advanced) ‚Äî Create a real-world portfolio project.\n",
    "\n",
    "Cybersecurity Pathway:\n",
    "1. Intro to Cybersecurity (Beginner) ‚Äî Understand basic security concepts.\n",
    "2. Network Security (Intermediate) ‚Äî Learn to secure communication channels.\n",
    "3. Ethical Hacking (Advanced) ‚Äî Test systems for vulnerabilities ethically.\n",
    "\n",
    "UI/UX Design Pathway:\n",
    "1. Intro to UI/UX (Beginner) ‚Äî Learn the basics of user interface and experience.\n",
    "2. Wireframing & Prototyping (Intermediate) ‚Äî Create interactive prototypes.\n",
    "3. UI/UX Capstone (Advanced) ‚Äî Complete a design project for a real client.\n",
    "\n",
    "Tips for Learning:\n",
    "- Always build projects alongside learning theory.\n",
    "- Review and adapt your learning roadmap every 2 months.\n",
    "- Start from your current skill level and progress gradually.\n",
    "\"\"\")\n",
    "\n",
    "# üìÑ Load & Split content\n",
    "loader = TextLoader(filename)\n",
    "documents = loader.load()\n",
    "splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "texts = splitter.split_documents(documents)\n",
    "\n",
    "# üîç Vector store (FAISS for quick Colab testing)\n",
    "# The `HuggingFaceEmbeddings` import is correct and will use the model locally\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# üéØ Prompt for LearnMate\n",
    "template = \"\"\"\n",
    "You are LearnMate, an AI learning coach.\n",
    "User Question: {question}\n",
    "Based on the student's interests, skill level, and goals, give a personalized learning pathway.\n",
    "Suggest specific courses, explain why they fit, and provide tips for progression.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# üîó Chains\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "combine_chain = StuffDocumentsChain(llm_chain=llm_chain)\n",
    "\n",
    "rag_chain = RetrievalQA(\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    combine_documents_chain=combine_chain,\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "def ask_learnmate(query):\n",
    "    \"\"\"\n",
    "    Function to handle the Gradio input and generate a response.\n",
    "    \"\"\"\n",
    "    if not query:\n",
    "        return \"Please enter a question.\"\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.run(query)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå An error occurred: {str(e)}\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=ask_learnmate,\n",
    "    inputs=gr.Textbox(label=\"Ask LearnMate\", placeholder=\"e.g. How do I become a frontend developer?\"),\n",
    "    outputs=gr.Textbox(label=\"LearnMate's Advice\"),\n",
    "    title=\"LearnMate ‚Äî Personalized Course Pathways\",\n",
    "    description=\"Get a personalized learning roadmap for your career goals in frontend development, cybersecurity, or UI/UX.\",\n",
    "    theme=\"default\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
